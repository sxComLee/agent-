---
标题: 比R1快8倍，思考深度还翻倍 - 智谱开源了整套六个大模型（附三大平台，支持推理/沉思/基础模型）
链接: https://mp.weixin.qq.com/s/80FRya6I5daPF_LoPq5YCQ?scene=1
作者: "[[coze]]"
创建时间: 2025-04-22T12:16:46+08:00
摘要: 
tags:
  - clippings
字数: "203"
状态: 未开始
---

最后，让我们用大白话来概括：

1. **有自己的思想**：Agent不仅能做事情，还能思考。他们有自己的想法和目标，并且会根据这些想法和目标来做出选择。
    
2. **自己作主**：Agent是能自己拿主意的。他们不是被其他人或东西牵着鼻子走，而是可以自己决定要做什么。
    
3. **承担责任**：Agent得为自己的行为承担后果。如果他们做了好事，可能会得到表扬；如果做了不好的事，可能就会受到批评或惩罚。
    
4. **有社会连接**：不同Agent可以进行彼此交流，分享自己所知道的事情，并能通过交换信息形成一张密集的关系网络。

**基于LLM的AI Agent**

  

好了，讲了这么多，终于要讲到基于大型语言模型的AI Agent了。想必大家现在都已经对AI Agent在概念有了更深刻的理解，接下来我们来详细解读一下基于大型语言模型的AI Agent。

![[_resources/Agent探究/abe66061e1d9aa51b5905a92c4ef7410_MD5.webp]]

  

  

## 10.1 大脑模块(Brain)

大脑模块（Brain）是AI Agent智能行为的核心，它是一个高度集成的系统，负责处理信息、做出决策和规划行动。这个模块通常基于大型语言模型(如Llama或GPT)，这些模型在海量文本数据上进行训练，赋予了Agent强大的自然语言理解和生成能力。大脑模块不仅包含了丰富的语言知识，如词法、句法、语义学和语用学，还融入了广泛的常识知识，帮助Agent做出符合现实世界的合理决策。

此外，大脑模块还集成了特定领域的专业知识，使Agent能够在专业领域内执行复杂任务。它具备记忆能力，能够存储和检索过去的观察、思考和行动序列，这对于处理连续任务和解决复杂问题至关重要。大脑模块还具备推理能力，可以基于证据和逻辑进行决策，并通过规划能力将复杂任务分解为可管理的子任务，并制定相应的行动计划。

计划反思机制使得Agent能够评估和完善其策略，以适应不断变化的环境。大脑模块还支持任务泛化，使Agent能够根据指令完成在训练阶段未遇到的新任务。上下文学习能力让Agent能够从给定的示例中快速学习并适应新任务，而持续学习机制则确保了在不断学习新知识的同时，能够有效地避免灾难性遗忘，保持知识的持续更新和累积。

![[_resources/Agent探究/f9bf53c2d38f5bae4f86a5c33bf230e3_MD5.webp]]

在接收到感知模块处理过的信息后，大脑模块首先会访问存储系统，在那里检索相关知识并从记忆中提取信息。这些步骤对于AI Agent来说极其重要，因为它们帮助Agent制定计划、进行推理，并做出明智的决策。

此外，大脑模块还能记录Agent过去的观察、思考和行动，无论是以摘要形式、矢量还是其他数据结构。同时，它也不断更新常识和专业知识库，以便未来使用。基于大型语言模型的AI Agent还具备出色的概括和迁移能力，使其能够适应新奇或陌生的场景。

  

## 10.2 感知模块(Perception)

感知模块的设计初衷在于极大地拓展Agent的感知视野，不仅仅局限于文字的范畴，而是迈向一个更为丰富多元的领域。这个领域融合了文字、听觉和视觉等多种模态，使得Agent能够以一种更加接近人类的方式去感知和理解周围的世界。

![[_resources/Agent探究/4134f6c257abf2b6e50ea5b50b542151_MD5.webp]]

- **文本输入**
    

AI Agent通过文本输入与人类进行交流，能够理解用户文本中明确的内容以及隐含的信念、愿望和意图。利用强化学习技术，Agent能够感知并推断用户的偏好，实现个性化和准确的回应。此外，Agent展现出的零样本学习能力使其能够处理全新的任务，无需针对特定任务的微调。

- **视觉输入**
    

视觉输入为AI Agent提供了丰富的环境信息，包括物体的属性、空间关系和场景布局。Agent可以通过生成图像的文本描述（图像标题）来理解图像内容。同时，Transformer模型的应用使得Agent能够直接对视觉信息进行编码和整合，提高了视觉感知能力。通过在视觉编码器和LLM之间添加可学习的接口层，Agent能够更好地对齐视觉和语言信息。

- **听觉输入**
    

听觉输入方面，AI Agent能够利用LLMs作为控制中心，调用现有的音频处理模型库来感知音频信息。通过音频频谱图的转换，Agent能够将音频信号的有效编码，实现对音频信息的理解和处理。

- **其他输入**
    

除了文本、视觉和听觉输入，AI Agent还可能配备更丰富的感知模块，如触觉、嗅觉以及对环境温湿度的感知能力。指向指令的引入使得Agent能够通过用户的手势或光标与图像交互。此外，通过集成激光雷达、GPS、IMU等硬件设备，Agent能够获得更全面的三维空间和运动感知能力。

  

10.3 行动模块（Action）

行动模块，作为人工智能体系中的关键组成部分，扮演着类似于人类大脑在感知环境后的角色。它负责接收来自感知模块的丰富信息，这些信息可能包括文字、声音、图像等多模态数据。正如人类大脑所做的，行动模块首先对这些信息进行整合，构建出一个全面的情境理解。

在这个整合的基础上，行动模块进一步分析信息，提炼出关键要素，进行逻辑推理。它模拟人类大脑的决策过程，评估不同行动方案的可行性和预期结果，从而选择最优的行动路径。这个过程涉及到复杂的算法和模型，包括但不限于决策树、强化学习、规则引擎等。

决策确定之后，行动模块则负责将决策转化为具体的行动指令。在人类中，这一过程由大脑通过神经系统控制身体完成。而在人工智能系统中，行动模块则通过工具(Tools)，来驱动机器人或虚拟角色进行相应的动作。

这些行动可以是适应环境的反应，如在导航模块的辅助下躲避障碍物，确保行动的顺畅和安全，或是在社交互动中发起交谈，建立联系。

![[_resources/Agent探究/35b26ca2eb8dd35776518298322ba0fc_MD5.webp]]

- **文本输出**
    

LLM-based Agent利用基于Transformer的语言生成模型，展现出卓越的文本生成能力，文本质量在流畅性、相关性、多样性和可控性方面都非常出色，使其成为强大的语言生成器。

- **工具使用**
    

工具是使用者能力的延伸。在面对复杂任务时，人类会使用工具来简化任务的解决过程并提高效率，从而节省时间和资源。同样，如果Agent也学会使用和利用工具，就有可能更高效、更高质量地完成复杂任务。LLM-based Agent在某些方面存在局限性，使用工具可以增强Agent的能力。

理解工具：Agent有效使用工具的前提是全面了解工具的应用场景和调用方法。没有这种理解，Agent使用工具的过程将变得不可信，也无法真正提高Agent的能力。利用LLM 强大的zero-shot learning和few-shot learning能力，Agent可以通过描述工具功能和参数的zero-shot demonstartion或提供特定工具使用场景和相应方法演示的少量提示来获取工具知识。这些学习方法与人类通过查阅工具手册或观察他人使用工具进行学习的方法类似。在面对复杂任务时，单一工具往往是不够的。因此，Agent应首先以适当的方式将复杂任务分解为子任务，然后有效地组织和协调这些子任务，这有赖于LLM的推理和规划能力，当然也包括对工具的理解。

使用工具：Agent学习使用工具的方法主要包括从demonstartion中学习和从reward中学习（清华有一篇从训练数据中学习的文章）。这包括模仿人类专家的行为，以及了解其行为的后果，并根据从环境和人类获得的反馈做出调整。环境反馈包括行动是否成功完成任务的结果反馈和捕捉行动引起的环境状态变化的中间反馈；人类反馈包括显性评价和隐性行为，如点击链接。

- **具身智能**
    

在追求人工通用智能（AGI）的征途中，具身Agent（Embodied Agent）正成为核心的研究范式，它强调将智能系统与物理世界的紧密结合。具身Agent的设计灵感源自人类智能的发展，认为智能不仅仅是对预设数据的处理，更多地来自于与周遭环境的持续互动和反馈。

与传统的深度学习模型相比，LLM-based Agent不再局限于处理纯文本信息或调用特定工具执行任务，而是能够主动地感知和理解其所在的物理环境，进而与其互动。这些 AI Agent利用其内部丰富的知识库，进行决策并产生具体行动，以此改变环境，这一系列的行为被称为“具身行动”。

具身行动的潜力在多个方面得到了验证。首先，它解决了传统强化学习（RL）算法在数据效率、泛化能力以及处理复杂问题时的局限性。LLM-based Agent通过联合训练机器人数据与视觉语言数据，实现了显著的转移能力，同时几何输入表示法提升了训练数据的利用效率。

在行动规划方面，具身Agent采用了分层强化学习方法和新兴的推理能力，使其能够无缝应对复杂任务，并根据环境反馈动态调整行动计划。具身行动主要包括观察、操纵和导航，这些能力使Agent能够获取环境信息、执行任务并动态改变位置。

具体来说，观察是Agent获取环境信息的主要方式，而操纵任务如物体重新排列和桌面操作，需要 AI Agent精确观察和整合子目标。导航能力则允许Agent根据环境反馈和内部地图动态改变位置，进行远距离操作。

通过整合这些功能，具身Agent能够完成复杂的任务，如自主探索环境并回答多模态问题。它们在特定数据集上训练后，能够生成高级策略命令，控制低级策略实现特定子目标。

  

|   |
|---|
|本章节部分引用：《The Rise and Potential of Large Language Model Based Agents: A Survey》：https://arxiv.org/pdf/2309.07864v1|

  

  

  

**十一、AI Agent——

Prompt-tuning VS Fine-tuning

**

  

  

在之前的讨论中，我们提到了AI Agent的三大核心组成部分，其中“大脑模块”（Brain）扮演着至关重要的角色。而激活这个“大脑模块”的关键之一就是Prompt。无论是在角色定义、知识处理还是逻辑规划的每一个环节，Prompt都发挥着不可或缺的作用。通过这些讨论，你可能已经明白为什么学习掌握Prompt技术如此重要——没有它，你几乎无法有效地操控一个AI Agent。

![[_resources/Agent探究/c6a563da1f68988b439667be30bfef86_MD5.webp]]

图Prompt与AI Agent的关系

  

  

11.1制作AI Agent的两种方式

![[_resources/Agent探究/6fe643a8c7a258854d79b68e901534ab_MD5.webp]]

图 10.1.1创建AI Agent的两种手段（来自李博杰的个人博客）

  

不过，虽然Prompt在激活和运用AI Agent的“大脑模块”中扮演着关键角色，但它并非没有缺点。一个很直观的问题是：_**使用的Prompt越长，消耗的Token也就越多。一个公众人物公开披露的个人信息（身份、言行等），转换成Token数可能高达数百万。这还不考虑模型是否能够处理这么多Token的问题，仅仅是每次推理所需支付的成本——无论是金钱还是时间——都可能非常高昂。**_

|   |
|---|
|_**所以，单纯通过****Prompt来构建大脑模块（Prompt-tuing），一般适合“无趣的灵魂”，即拟人化不是那么重的情况。**_|

紧接上面的总结，那”有趣的灵魂"咋办呢？目前，针对"有趣的灵魂"最直接的解决方式就是通过微调一个定向模型来达到上述效果。与Prompt相比，基于微调的方法可以视为将信息直接“记忆”在AI的“大脑模块”中。微调过程本质上是一个信息压缩和整合的过程，它能将例如三万条推特中的零散信息有效地整理并嵌入到大型模型的权重中，且权重占比不到1%。这种方法不仅提高了信息提取的效率，还减少了每次查询或应用时所需处理的数据量，从而优化了性能和成本。

|   |
|---|
|_**"面对有趣的灵魂"，一般创建方式是两种结合，即Prompt-tuning +Fine-tuning。**  <br>_|

  

11.2如何取舍？

当你准备在正式项目中部署一个AI Agent时，请牢记以下十条建议，并根据实际情况做出相应的调整：

1. _**尝试使用提示：在考虑微调模型之前，首先尝试使用提示来满足需求。只有当提示无法满足质量、性能或成本目标时，再考虑进行微调。**_
    

2. _**编写并测试提示：通过编写和测试提示来验证任务的可行性，这可以作为微调的基线。如果提示已经能够达到要求，那么微调可能会进一步提升效果；反之，则微调成功的可能性较低。**_
    

3. _**关注数据质量：始终检查并确保数据质量，必要时删除或修正问题数据。高质量的数据是模型优良表现的基础。**_
    

4. _**使用真实场景数据进行微调：即使数据存在一些不完美，只要它们能够代表真实场景下的整体分布，就可以用于微调。**_
    

5. _**保留测试集：确保不要将所有数据都用于训练，应留出一部分作为测试集以评估模型性能。**_
    

6. _**选择适当的模型规模：选择与任务难度相匹配的模型规模。过大或过小的模型都可能影响效率和效果。**_
    

7. _**设立快速评估指标：制定可以快速计算的评估指标，以便进行多次日常评估和快速迭代。**_
    

8. _**执行完整评估：定期进行全面评估，确保快速评估指标与最终目标指标保持一致。**_
    

9. _**持续优化：不要仅仅满足于一次性的训练结果。持续地优化和更新模型及其相关流程是至关重要的。**_
    

10. _**灵活应变：以上建议并非铁律。根据项目具体情况灵活调整策略，找到最适合自己项目需求的方法。**_
    

  

遵循这些原则将帮助你更有效地部署AI Agent，并最大化其在实际应用中的价值和效果。然而，重要的是要理解，这些建议并不是一成不变的规则。每个项目都有其独特的环境和需求，因此灵活性至关重要。只有通过根据项目的具体情况进行调整和优化，才能确保所部署的AI Agent能够在特定场景下发挥最大的效能。实践中可能会遇到各种预料之外的挑战，这时候创造性地修改和适应这些建议将是解决问题的关键。

  

|   |
|---|
|本章部分引用李博杰的个人博客《AI Agent 应该更有趣还是更有用？》：https://01.me/2024/03/ai-agents-entertaining-or-useful/|

  

  

  

  

**十二、现在的AI Agent 真的是”人“吗？**

  

  

我们对人工智能的追求，始终围绕着一个宏伟的目标：将AI Agent的概念塑造得更接近于“人”，更确切地说，是接近“智人”的特质。那么，在这个探索的旅程中，我们又该如何定义“智人”呢？或者说，我们从何时开始认为人类具有智慧？

从人类学的角度来看，当人类掌握了钻木取火的技术，那一刻，我们才真正迈入了“拥有智慧”的门槛。这一行为不仅标志着人类对自然界的深刻理解和利用，也象征着人类文明的一大飞跃。

_**反观当下的**__**AI Agent，尽管它们已经能够熟练地使用工具，但距离自主制造和创造工具的阶段，仍有一段长路要走。它们在模仿人类行为和决策方面取得了显著进步，但要达到人类在工具创造和文明发展上的成就，仍需不断的探索和突破。**_

然而，正是这种对未来可能性的期待，激励着我们不断前行。我满怀希望地期待着那一天的到来——AI Agent不仅能使用工具，更能创造工具，真正展现出“智人”的光辉。

![[_resources/Agent探究/889708e56b15f48fc2a11fbc3180bf7c_MD5.webp]]

图 电影《太空漫游2001》“望月者”获得智慧那一刻

  

  

  

  

**十三、写给读者的话**

  

  

首先，非常感谢大家的阅读和支持。我深知，在这个信息爆炸的时代，能吸引到大家的关注和喜爱，是我莫大的荣幸。我的文章都是在繁忙之余，倾注心血、精心打磨而成。我希望通过文字，与大家分享知识、思考和见解，搭建起作者与读者之间沟通的桥梁。

AI Agent作为通往AGI的重要途径之一，无疑值得我们深入学习和探讨。我们开设这个专栏的主要目的，一方面是为了正本清源地解读AI Agent的内涵，传承先贤的智慧，让上一代的成果在当代继续发扬光大。另一方面，我们也希望通过编写文章，与大家共同探讨AI agent的前沿话题，分享最新的研究成果和实践经验。

我相信，通过这个系列，不仅可以传承知识，更可以激发思考，碰撞出思想的火花。我期待与你一起，探索AI Agent的无限可能，共同见证人工智能的蓬勃发展。

再次感谢大家的关注和支持，希望这个系列能给大家带来有价值的信息和启发！