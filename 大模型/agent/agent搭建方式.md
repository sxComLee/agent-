
## 单 agent （LLM 模式）

这是一种最常规的搭建方式，适合处理简单的任务。如果要处理复杂任务，必须编写非常详细和冗长的提示词。而且需要添加各种插件和工作流等，这增加了调试智能体的复杂性。调试时任何一处细节改动，都有可能影响到智能体的整体功能，实际处理用户任务时，处理结果可能与预期效果有较大出入。

所以它的场景是：

1. 适用于简单的闲聊，对时延要求不高
    
2. 不适用于复杂的逻辑场景
    
3. 添加插件/工作流会让速度大幅变慢（下文解释原理）
    
## 多 agents
    
为了解决单 Agent 的上述问题，扣子提供了多 Agent 模式，该模式下您可以为智能体添加多个 Agent，并连接、配置各个 Agent 节点，通过多节点之间的分工协作来高效解决复杂的用户任务。

多 Agent 模式通过以下方式来简化复杂的任务场景。
> 
> - 您可以为不同的 Agent 配置独立的提示词，将复杂任务分解为一组简单任务，而不是在一个智能体的提示词中设置处理任务所需的所有判断条件和使用限制。
>     
> - 多 Agent 模式允许您为每个 Agent 节点配置独立的插件和工作流。这不仅降低了单个 Agent 的复杂性，还提高了测试智能体时 bug 修复的效率和准确性，您只需要修改发生错误的 Agent 配置即可。
>     

所以它的场景是：

1. 适用于复杂的逻辑场景
    
2. 对时延要求不高
    
3. 添加插件/工作流会让速度大幅变慢（下文解释原理）
    

## 2.3 单 agent （对话流模式）

这种模式系统只定义了开始和结束节点，中间的逻辑完全由用户设计，所以足够灵活也足够高效，但用户往往无从下手。所以我们提供了 [[对外] Agent 联网搜索+设备控制+闲聊+长期记忆搭建](https://bytedance.larkoffice.com/docx/CEJedaaf8oxJMox7g6DcOBnAnbh)，但架构为什么这样设计，时延问题是怎么解决的，我们继续分解。